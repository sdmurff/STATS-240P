---
title: "STATS240P-Homework 1"
author: "Scott Murff"
date: " Due October 19, 2015"
output: pdf_document
---

# Exercise 1.2

Using the F-test of a general linear hypothesis, show how to test the following hypotheses on the regression coefficients:

## (a) 
$H_0 : \beta_0 = \beta_2$.

Recall that the full model under consideration is:

$$ y_i = \beta_0 + \beta_1x_{i1}
                 + \beta_2x_{i2}
                 + \beta_3x_{i3}
                 + \epsilon_i, 1\leq i \leq n$$
                 
or in matrix notation:

$$\boldsymbol{Y} = \boldsymbol{X\beta} + \boldsymbol{\epsilon}, \,where\, \boldsymbol{Y}\,and\,\boldsymbol{\epsilon} \,are\, \left(n\,x\,1\right), \boldsymbol{X} \,is\, \left(n\,x\,4\right),  \,and\,  \boldsymbol{\beta} \, is \left(\,4\,x\,1\right)$$.
                                               
Since $\beta_0 = \beta_2$ implies $\beta_0 - \beta_2 = 0$, $H_0$ can be represented as $\boldsymbol{\beta}^T\mathbf{c} = 0$ where:

$$\boldsymbol{\beta}^T = \left(\beta_0\,\beta_1\,\beta_2\,\beta_3\right)$$ 

and 

$$\mathbf{c} = \left(\begin{array}{c}1\\0\\-1\\0\end{array}\right)$$

This constraint results in the following restricted model:

$$ y_i = \beta_0\left(1+x_{i2}\right) + \beta_1x_{i1}
                                      + \beta_3x_{i3}
                                      + \epsilon_i$$
or in matrix notation:

$$\boldsymbol{Y} = \boldsymbol{\tilde{X}\tilde{\beta}} + \boldsymbol{\epsilon}, \,where\, \boldsymbol{Y}\,and\,\boldsymbol{\epsilon} \,are\, \left(n\,x\,1\right), \boldsymbol{\tilde{X}} \,is\, \left(n\,x\,3\right),  \,and\,  \boldsymbol{\tilde{\beta}} \, is \left(\,3\,x\,1\right)$$.

Once the full and restricted models are defined, performing an F-test then proceeds in the following steps:

1. Estimate $\boldsymbol{\beta}$ in the full model using the relationship $\boldsymbol{\hat{\beta}} = \left(\boldsymbol{X}^T\boldsymbol{X}\right)^{-1}\boldsymbol{X}^T\boldsymbol{Y}$. It follows that $\hat{\boldsymbol{Y}} = \boldsymbol{X}\left(\boldsymbol{X}^T\boldsymbol{X}\right)^{-1}\boldsymbol{X}^T\boldsymbol{Y}$. Note that $\mathop{\mathbb{E\left(\epsilon\right)}} = \boldsymbol{0}$ 
2. Compute the RSS of the full model by $||\boldsymbol{Y}-\hat{\boldsymbol{Y}}||^2$
3. Estimate $\boldsymbol{\tilde{\beta}}$ in the full model using the relationship $\boldsymbol{\hat{\tilde{\beta}}} = \left(\boldsymbol{\tilde{X}}^T\boldsymbol{\tilde{X}}\right)^{-1}\boldsymbol{\tilde{X}}^T\boldsymbol{Y}$. It follows that $\hat{\boldsymbol{Y_0}} = \boldsymbol{\tilde{X}}\left(\boldsymbol{\tilde{X}}^T\boldsymbol{\tilde{X}}\right)^{-1}\boldsymbol{\tilde{X}}^T\boldsymbol{Y}$. Note that $\mathop{\mathbb{E\left(\epsilon\right)}} = \boldsymbol{0}$ 
4. Compute the RSS of the restricted model by $||\boldsymbol{Y}-\hat{\boldsymbol{Y_0}}||^2$

The RSS of the full and the RSS of restricted model can be viewed geometrically as in the picture below (image taken from course textbook)

![](/Users/scottmurff/Documents/Stanford/STATS-240P/Ftest.PNG)

As can be seen in the picture, $||\boldsymbol{Y}-\hat{\boldsymbol{Y_0}}||^2 = ||\boldsymbol{Y}-\hat{\boldsymbol{Y}}||^2 + ||\hat{\boldsymbol{Y}}-\hat{\boldsymbol{Y_0}}||^2$ 

This relationship holds by Pythagoras' theorem for projections and the fact that $||\boldsymbol{Y}-\hat{\boldsymbol{Y}}||^2$ and $||\hat{\boldsymbol{Y}}-\hat{\boldsymbol{Y_0}}||^2$ are orthogonal.

We want a test that will tell us if the term $||\hat{\boldsymbol{Y}}-\hat{\boldsymbol{Y_0}}||^2$ is sufficiently large to conclude that the full model is superior to the restricted model. So we proceed to step 5.

5. Construct an F-Statistic as follows: $F = \dfrac{\frac{||\hat{\boldsymbol{Y}}-\hat{\boldsymbol{Y_0}}||^2}{p-r}}{\frac{||\boldsymbol{Y}-\hat{\boldsymbol{Y}}||^2}{n-p}}$, where the degrees of freedom in the denominator are n-4, and the degrees of freedom in the numerator are 4-3. Under the null $F \overset{H_0}{\sim} F(1,n-4)$. If the value of $F$ is larger than the value of the quantile $F_{1,n-4;\alpha}$ then we reject the null and conclude that the full model is superior. Otherwise we fail to reject the null and use the restricted model.

## (b) 
$H_0 : \beta_1 + \beta_2 = 3\beta_3$.

To test this hypothesis we follow the same logic and procedure outlined in a) above with the following adjustments:

1. In this case $H_0$ can be represented as $\beta_1 + \beta_2 - 3\beta_3 = 0$ or $\boldsymbol{\beta}^T\mathbf{c} = 0$ where:

$$\boldsymbol{\beta}^T = \left(\beta_0\,\beta_1\,\beta_2\,\beta_3\right)$$ 

and 

$$\mathbf{c} = \left(\begin{array}{c}0\\1\\1\\-3\end{array}\right)$$

A convenient way to represent the constraint to faciliate esimating the reduced model is to write $\beta_1 = 3\beta_3 -\beta_2$. We can then plug $\beta_1$ back into the full model as follows:
$$ y_i = \beta_0 + \left(3\beta_3-\beta_2\right)x_{i1}
                 + \beta_2x_{i2}
                 + \beta_3x_{i3}
                 + \epsilon_i, 1\leq i \leq n$$
                 
After algebraic manipulation, this reduces to:

$$ y_i = \beta_0 + \beta_2\left(x_{i2}-x_{i1}\right)
                 + \beta_3\left(3x_{i1}-x_{i3}\right)
                 + \epsilon_i, 1\leq i \leq n$$
or in matrix notation:

$$\boldsymbol{Y} = \boldsymbol{\tilde{X}\tilde{\beta}} + \boldsymbol{\epsilon}, \,where\, \boldsymbol{Y}\,and\,\boldsymbol{\epsilon} \,are\, \left(n\,x\,1\right), \boldsymbol{\tilde{X}} \,is\, \left(n\,x\,3\right),  \,and\,  \boldsymbol{\tilde{\beta}} \, is \left(\,3\,x\,1\right)$$.

After obtaining $\boldsymbol{\hat{\tilde{\beta}}}$ from the reduced model and $\boldsymbol{\hat{\beta}}$ from the full model we can compute $\boldsymbol{\hat{Y}} = \boldsymbol{X}\boldsymbol{\hat{\beta}}$ and $\boldsymbol{\hat{Y_0}} = \boldsymbol{\tilde{X}}\boldsymbol{\hat{\tilde{\beta}}}$ and then compute the F statistic $F = \dfrac{\frac{||\hat{\boldsymbol{Y}}-\hat{\boldsymbol{Y_0}}||^2}{4-3}}{\frac{||\boldsymbol{Y}-\hat{\boldsymbol{Y}}||^2}{n-4}}$. Under the null $F\overset{H_0}{\sim} F(1,n-4)$. If the value of $F$ is larger than the value of the quantile $F_{1,n-4;\alpha}$ then we reject the null and conclude that the full model is superior. Otherwise we fail to reject the null and use the restricted model.

# Exercise 1.6

## (a)

```{r echo=FALSE, warning=FALSE}
library(knitr)
read_chunk('/Users/scottmurff/Documents/Stanford/STATS-240P/Homework 1.R')
```

```{r HW1, echo=FALSE, results='hide', eval=TRUE, warning=FALSE, message=FALSE}
```

```{r a1_6_1, fig.height=4, fig.width=6}
```

An initial glance at the plot suggests that the i.i.d. assumption for Pfizer returns is a reasonable one. After adding a horizontal line at 0 and a verical line at March 8, 1999 there does appear to be a slight downward shift of the mean of the returns after this date. It is not easy to see visually however from a scatter plot. A difference is more clear by looking at a box plot as shown below:

```{r a1_6_2, fig.height=4, fig.width=6}
```

## (b)
A regression summary is shown below:
```{r b1_6_1}
```

95 % confidence Intervals for the paramters are shown below:
```{r b1_6_2}
```

## (c)
Test $H_0 : \mu_1 = \mu_2$.

Testing $H_0$ can achieved by performing an F-test with the full model being $r_t = \mu_1\boldsymbol{1}_{\{t<t_0\}} + \mu_2\boldsymbol{1}_{\{t \geq t_0\}} + \epsilon_t$ and the reduced model being $r_t = \mu_1\boldsymbol{1}$. We fit the reduced model below and then carry out an F-test using anova commnand in R as shown below:

```{r c1_6_1}
```

As can be seen in the output above, the F-Statistic under the null is 6.009 resulting in a p-value of 0.01436. This provides sufficient evidence to reject $H_0 : \mu_1 = \mu_2$ at the 5% significance level and conclude that there is reasonably strong evidence $\mu_1$ and $\mu_2$ are different. 


# Exercise 2.2

# Exercise 2.3
